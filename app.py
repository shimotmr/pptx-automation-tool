import os
import uuid
import json
import shutil
import traceback
import requests

import streamlit as st
import streamlit.components.v1 as components
from pptx import Presentation

from ppt_processor import PPTAutomationBot


# =========================
# Config
# =========================
st.set_page_config(
    page_title="Aurotekæ•¸ä½è³‡æ–™åº« ç°¡å ±æ¡ˆä¾‹è‡ªå‹•åŒ–ç™¼å¸ƒå¹³å°",
    page_icon="ğŸ¤–",
    layout="wide",
)

LOGO_URL = "https://aurotek.com/wp-content/uploads/2025/07/logo.svg"
WORK_DIR = "temp_workspace"
HISTORY_FILE = "job_history.json"
SOURCE_FILENAME = "source.pptx"


# =========================
# CSS
# =========================
st.markdown(
    """
<style>
/* éš±è— Streamlit é è¨­ header */
header[data-testid="stHeader"] { display:none; }
.stApp > header { display:none; }

/* æ•´é«”é–“è·æ›´ç·Šæ¹Š */
.block-container{
  padding-top: 0.9rem !important;
  padding-bottom: 1.2rem !important;
}

/* ========= File Uploaderï¼ˆç˜¦èº«ã€ä¸­æ–‡åŒ–ã€ä¿®æ­£ç›´æ’é‡è¤‡ï¼‰ ========= */

/* éš±è—åŸæœ¬å…©è¡Œèªªæ˜ */
[data-testid="stFileUploaderDropzoneInstructions"] > div:first-child { display:none !important; }
[data-testid="stFileUploaderDropzoneInstructions"] > div:nth-child(2) { display:none !important; }

/* ç”¨æ›´çŸ­çš„ä¸­æ–‡æç¤º */
[data-testid="stFileUploaderDropzoneInstructions"]::before{
  content:"æ‹–æ”¾æˆ–é»æ“Šä¸Šå‚³";
  display:block;
  font-size:0.95rem;
  font-weight:700;
  line-height:1.15;
  margin:0;
}
[data-testid="stFileUploaderDropzoneInstructions"]::after{
  content:"å–®æª” 5GB Â· PPTX";
  display:block;
  font-size:0.75rem;
  color:#8a8a8a;
  margin-top:2px;
  line-height:1.15;
}

/* è®“ dropzone æ›´çŸ® */
section[data-testid="stFileUploaderDropzone"]{
  padding:0.55rem 0.9rem !important;
}

/* ====== é€™æ®µæ˜¯ã€Œç¸±æ’é‡è¤‡ç€è¦½æª”æ¡ˆã€çš„æ ¹æ²» ======
   ä»¥å‰ç”¨ color: transparent å¯èƒ½ç„¡æ³•è“‹æ‰å…§éƒ¨ spanï¼Œçª„å¯¬æœƒè®Šç›´æ’ã€‚
   æ”¹ç”¨ font-size:0 å¾¹åº•è®“åŸæ–‡å­—æ¶ˆå¤±ï¼Œå†ç”¨ ::after æ”¾ä¸­æ–‡ã€‚ */
div[data-testid="stFileUploader"] button{
  position:relative !important;
  font-size:0 !important;            /* âœ… åŸæœ¬æ–‡å­—å¾¹åº•æ¶ˆå¤±ï¼ˆé¿å…ç›´æ’ï¼‰ */
  line-height:0 !important;
  white-space:nowrap !important;
  writing-mode: horizontal-tb !important;
}
div[data-testid="stFileUploader"] button::after{
  content:"ç€è¦½æª”æ¡ˆ";
  font-size:0.95rem;
  line-height:1;
  color:#31333F;
  font-weight:600;
  position:absolute;
  left:50%; top:50%;
  transform:translate(-50%, -50%);
  white-space:nowrap;
  writing-mode: horizontal-tb;
}

/* st.info æ–‡å­—ç¨å¾®å°ä¸€é» */
[data-testid="stAlert"] p{
  font-size:0.85rem !important;
  line-height:1.35 !important;
}

/* ===== Results UI ===== */
.auro-result-wrap{
  border:1px solid rgba(49,51,63,.15);
  border-radius:14px;
  padding:14px 14px 8px 14px;
  background:#fff;
}
.auro-result-title{
  display:flex;
  align-items:center;
  gap:10px;
  font-size:1.15rem;
  font-weight:800;
  margin:0 0 8px 0;
}
.auro-pill{
  display:inline-block;
  padding:2px 10px;
  border-radius:999px;
  font-size:0.78rem;
  color:#0b5;
  background:rgba(0,170,85,.10);
  border:1px solid rgba(0,170,85,.25);
}
.auro-card{
  display:flex;
  align-items:center;
  justify-content:space-between;
  gap:10px;
  padding:12px 12px;
  margin:10px 0;
  border:1px solid rgba(49,51,63,.12);
  border-radius:12px;
  background:rgba(248,249,251,.7);
}
.auro-card .name{
  font-weight:700;
  color:#222;
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  max-width:70vw;
}
.auro-card a.btn{
  text-decoration:none !important;
  padding:8px 12px;
  border-radius:10px;
  background:#0B4F8A;
  color:white !important;
  font-weight:700;
  white-space:nowrap;
}
.auro-card a.btn:hover{
  filter:brightness(1.05);
}

/* æ‰‹æ©Ÿå†ç·Šä¸€é» */
@media (max-width:768px){
  .block-container{ padding-top:0.65rem !important; }
  .auro-card .name{ max-width:55vw; }
}
</style>
""",
    unsafe_allow_html=True,
)


# =========================
# Utilities
# =========================
def ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)


def clean_workspace() -> None:
    if os.path.exists(WORK_DIR):
        shutil.rmtree(WORK_DIR, ignore_errors=True)
    ensure_dir(WORK_DIR)


def write_source_to_workspace(file_bytes: bytes) -> str:
    """å›å‚³ source.pptx çš„å¯¦éš›è·¯å¾‘"""
    clean_workspace()
    source_path = os.path.join(WORK_DIR, SOURCE_FILENAME)
    with open(source_path, "wb") as f:
        f.write(file_bytes)
    return source_path


def load_history(filename: str):
    if not os.path.exists(HISTORY_FILE):
        return []
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data.get(filename, [])
    except Exception:
        return []


def save_history(filename: str, jobs):
    try:
        data = {}
        if os.path.exists(HISTORY_FILE):
            try:
                with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                    data = json.load(f)
            except Exception:
                data = {}
        data[filename] = jobs
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"History save failed: {e}")


def add_split_job(total_pages: int):
    st.session_state.split_jobs.insert(
        0,
        {
            "id": str(uuid.uuid4())[:8],
            "filename": "",
            "start": 1,
            "end": total_pages,
            "category": "æ¸…æ½”",
            "subcategory": "",
            "client": "",
            "keywords": "",
        },
    )


def remove_split_job(index: int):
    st.session_state.split_jobs.pop(index)


def validate_jobs(jobs, total_slides: int):
    errors = []
    for i, job in enumerate(jobs):
        task_label = f"ä»»å‹™ {i+1} (æª”å: {job['filename'] or 'æœªå‘½å'})"
        if not job["filename"].strip():
            errors.append(f"âŒ {task_label}: æª”æ¡ˆåç¨±ä¸èƒ½ç‚ºç©ºã€‚")
        if job["start"] > job["end"]:
            errors.append(f"âŒ {task_label}: èµ·å§‹é  ({job['start']}) ä¸èƒ½å¤§æ–¼ çµæŸé  ({job['end']})ã€‚")
        if job["end"] > total_slides:
            errors.append(f"âŒ {task_label}: çµæŸé  ({job['end']}) è¶…å‡ºäº†ç°¡å ±ç¸½é æ•¸ ({total_slides})ã€‚")

    sorted_jobs = sorted(jobs, key=lambda x: x["start"])
    for i in range(len(sorted_jobs) - 1):
        a, b = sorted_jobs[i], sorted_jobs[i + 1]
        if a["end"] >= b["start"]:
            errors.append(
                "âš ï¸ ç™¼ç¾é æ•¸é‡ç–Šï¼\n"
                f"   - {a['filename']} (ç¯„åœ {a['start']}-{a['end']})\n"
                f"   - {b['filename']} (ç¯„åœ {b['start']}-{b['end']})\n"
                f"   è«‹ç¢ºèªæ˜¯å¦é‡è¤‡åŒ…å«äº†ç¬¬ {b['start']} åˆ° {a['end']} é ã€‚"
            )
    return errors


def download_bytes_from_url(url: str):
    r = requests.get(url, stream=True, timeout=60)
    r.raise_for_status()
    return r.content


@st.cache_resource(show_spinner=False)
def get_bot():
    return PPTAutomationBot()


@st.cache_data(show_spinner=False)
def parse_ppt_preview(ppt_bytes: bytes):
    """å›å‚³ (total_slides, preview_data)"""
    ensure_dir(WORK_DIR)
    tmp_path = os.path.join(WORK_DIR, "__preview__.pptx")
    with open(tmp_path, "wb") as f:
        f.write(ppt_bytes)

    prs = Presentation(tmp_path)
    total = len(prs.slides)
    preview_data = []
    for i, slide in enumerate(prs.slides):
        txt = "ç„¡æ¨™é¡Œ"
        try:
            if slide.shapes.title and slide.shapes.title.text:
                txt = slide.shapes.title.text
        except Exception:
            pass
        if txt == "ç„¡æ¨™é¡Œ":
            for s in slide.shapes:
                if hasattr(s, "text") and isinstance(s.text, str) and s.text.strip():
                    txt = s.text.strip()[:20] + "..."
                    break
        preview_data.append({"é ç¢¼": i + 1, "å…§å®¹æ‘˜è¦": txt})
    return total, preview_data


def render_header():
    # é«˜åº¦æ”¹å¾—æ¯”è¼ƒç·Šå‡‘
    components.html(
        f"""
        <div style="
            width:100%;
            display:flex;
            flex-direction:column;
            align-items:center;
            justify-content:center;
            margin:2px 0 0 0;
            line-height:1.05;
        ">
            <img src="{LOGO_URL}" style="width:300px;height:auto;display:block;margin:0;" />
            <div style="
                margin-top:4px;
                width:300px;
                text-align:center;
                color:gray;
                font-size:1.0rem;
                font-weight:500;
                letter-spacing:2px;
            ">ç°¡å ±æ¡ˆä¾‹è‡ªå‹•åŒ–ç™¼å¸ƒå¹³å°</div>
        </div>
        """,
        height=74,
    )


def render_results_ui(file_prefix: str, final_results: list):
    links = []
    for res in final_results:
        if "final_link" in res:
            links.append((f"[{file_prefix}]_{res.get('filename','')}", res["final_link"]))

    st.markdown('<div class="auro-result-wrap">', unsafe_allow_html=True)
    st.markdown(
        f'<div class="auro-result-title">âœ… ç”¢å‡ºçµæœé€£çµ <span class="auro-pill">{len(links)} ç­†</span></div>',
        unsafe_allow_html=True,
    )

    if not links:
        st.info("æ²’æœ‰ç”¢ç”Ÿä»»ä½•çµæœé€£çµï¼Œè«‹æª¢æŸ¥æ˜¯å¦æœ‰ä»»å‹™è¢«è·³éã€‚")
        st.markdown("</div>", unsafe_allow_html=True)
        return

    for name, link in links:
        st.markdown(
            f"""
            <div class="auro-card">
              <div class="name">{name}</div>
              <a class="btn" href="{link}" target="_blank" rel="noopener">é–‹å•Ÿ Google Slides</a>
            </div>
            """,
            unsafe_allow_html=True,
        )

    st.markdown("</div>", unsafe_allow_html=True)


# =========================
# Core automation
# =========================
def execute_automation_logic(bot, source_path, file_prefix, jobs, auto_clean):
    main_progress = st.progress(0, text="æº–å‚™é–‹å§‹...")
    status_area = st.empty()
    detail_bar = st.empty()

    sorted_jobs = sorted(jobs, key=lambda x: x["start"])

    def update_detail(pct, text):
        detail_bar.progress(pct, text=text)

    def log(msg):
        print(f"[Log] {msg}")

    try:
        status_area.info("1ï¸âƒ£ æ­¥é©Ÿ 1/5ï¼šæå– PPT å…§å½±ç‰‡ä¸¦ä¸Šå‚³è‡³é›²ç«¯...")
        main_progress.progress(5, text="Step 1: å½±ç‰‡é›²ç«¯åŒ–")
        video_map = bot.extract_and_upload_videos(
            source_path,
            os.path.join(WORK_DIR, "media"),
            file_prefix=file_prefix,
            progress_callback=lambda fn, cur, tot: update_detail(
                cur / tot if tot else 0,
                f"Step 1ï¼šä¸Šå‚³ `{fn}` ({int((cur/tot)*100) if tot else 0}%)",
            ),
            log_callback=log,
        )
        detail_bar.empty()

        status_area.info("2ï¸âƒ£ æ­¥é©Ÿ 2/5ï¼šå°‡ PPT å…§çš„å½±ç‰‡æ›¿æ›ç‚ºé›²ç«¯é€£çµåœ–ç‰‡...")
        main_progress.progress(25, text="Step 2: é€£çµç½®æ›")
        mod_path = os.path.join(WORK_DIR, "modified.pptx")
        bot.replace_videos_with_images(
            source_path,
            mod_path,
            video_map,
            progress_callback=lambda cur, tot: update_detail(
                cur / tot if tot else 0,
                f"Step 2ï¼šè™•ç†æŠ•å½±ç‰‡ {cur}/{tot}",
            ),
        )
        detail_bar.empty()

        status_area.info("3ï¸âƒ£ æ­¥é©Ÿ 3/5ï¼šé€²è¡Œæª”æ¡ˆå£“ç¸®èˆ‡ç˜¦èº«...")
        main_progress.progress(45, text="Step 3: æª”æ¡ˆç˜¦èº«")
        slim_path = os.path.join(WORK_DIR, "slim.pptx")
        bot.shrink_pptx(
            mod_path,
            slim_path,
            progress_callback=lambda cur, tot: update_detail(
                cur / tot if tot else 0,
                f"Step 3ï¼šè™•ç†å…§éƒ¨æª”æ¡ˆ {cur}/{tot}",
            ),
        )
        detail_bar.empty()

        status_area.info("4ï¸âƒ£ æ­¥é©Ÿ 4/5ï¼šä¾è¨­å®šæ‹†åˆ†ç°¡å ±ä¸¦ä¸Šå‚³è‡³ Google Slides...")
        main_progress.progress(65, text="Step 4: æ‹†åˆ†ç™¼å¸ƒ")
        results = bot.split_and_upload(
            slim_path,
            sorted_jobs,
            file_prefix=file_prefix,
            progress_callback=lambda fn, cur, tot: update_detail(
                cur / tot if tot else 0,
                f"Step 4ï¼šä¸Šå‚³ `{fn}` ({int((cur/tot)*100) if tot else 0}%)",
            ),
            log_callback=log,
        )
        detail_bar.empty()

        oversized = [r for r in results if r.get("error_too_large")]
        if oversized:
            st.error("â›”ï¸ æµç¨‹çµ‚æ­¢ï¼šåµæ¸¬åˆ°æ‹†åˆ†å¾Œçš„æª”æ¡ˆéå¤§ï¼ˆè¶…é Google 100MB é™åˆ¶ï¼‰ã€‚")
            for j in oversized:
                st.error(f"âŒ ä»»å‹™ã€Œ{j['filename']}ã€ä»æœ‰ {j['size_mb']:.2f} MB")
            st.warning("ğŸ’¡ å»ºè­°ï¼šç¸®å°è©²ä»»å‹™é æ•¸ç¯„åœï¼Œæ‹†æˆå¤šå€‹å°ä»»å‹™å¾Œå†è·‘ã€‚")
            return

        status_area.info("5ï¸âƒ£ æ­¥é©Ÿ 5/5ï¼šå„ªåŒ–ç·šä¸Šç°¡å ±çš„å½±ç‰‡æ’­æ”¾å™¨...")
        main_progress.progress(85, text="Step 5: å…§åµŒå„ªåŒ–")
        final_results = bot.embed_videos_in_slides(
            results,
            progress_callback=lambda cur, tot: update_detail(
                cur / tot if tot else 0,
                f"Step 5ï¼šå„ªåŒ–ä»»å‹™ {cur}/{tot}",
            ),
            log_callback=log,
        )
        detail_bar.empty()

        status_area.info("ğŸ“ æœ€å¾Œæ­¥é©Ÿï¼šå°‡æˆæœå¯«å…¥ Google Sheets è³‡æ–™åº«...")
        main_progress.progress(95, text="Final: å¯«å…¥è³‡æ–™åº«")
        bot.log_to_sheets(final_results, log_callback=log)

        main_progress.progress(100, text="ğŸ‰ ä»»å‹™å…¨éƒ¨å®Œæˆï¼")
        status_area.success("ğŸ‰ æ‰€æœ‰è‡ªå‹•åŒ–æµç¨‹åŸ·è¡Œå®Œç•¢ï¼")

        if auto_clean:
            clean_workspace()
            st.toast("å·²è‡ªå‹•æ¸…é™¤æš«å­˜æª”æ¡ˆã€‚", icon="ğŸ§¹")

        st.divider()
        render_results_ui(file_prefix, final_results)

    except Exception as e:
        st.error(f"åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        with st.expander("æŸ¥çœ‹è©³ç´°éŒ¯èª¤è³‡è¨Š"):
            st.code(traceback.format_exc())


# =========================
# State init
# =========================
ensure_dir(WORK_DIR)

if "split_jobs" not in st.session_state:
    st.session_state.split_jobs = []
if "ppt_meta" not in st.session_state:
    st.session_state.ppt_meta = {"total_slides": 0, "preview_data": []}
if "current_file_name" not in st.session_state:
    st.session_state.current_file_name = None
if "source_bytes" not in st.session_state:
    st.session_state.source_bytes = None


# =========================
# UI
# =========================
render_header()

st.info("åŠŸèƒ½èªªæ˜ï¼š ä¸Šå‚³PPT â†’ ç·šä¸Šæ‹†åˆ† â†’ å½±ç‰‡é›²ç«¯åŒ– â†’ å…§åµŒå„ªåŒ– â†’ ç°¡å ±é›²ç«¯åŒ– â†’ å¯«å…¥å’Œæ¤¿è³‡æ–™åº«")

# Bot initï¼ˆå¿«å–ï¼‰
try:
    bot = get_bot()
    if not getattr(bot, "creds", None):
        st.warning("âš ï¸ ç³»çµ±æœªæª¢æ¸¬åˆ°æœ‰æ•ˆæ†‘è­‰ (Secrets)ã€‚")
except Exception as e:
    st.error(f"Bot åˆå§‹åŒ–å¤±æ•—: {e}")
    bot = None

# Step 1
with st.container(border=True):
    st.subheader("ğŸ“‚ æ­¥é©Ÿä¸€ï¼šé¸æ“‡æª”æ¡ˆä¾†æº")

    input_method = st.radio("ä¸Šå‚³æ–¹å¼", ["æœ¬åœ°æª”æ¡ˆ", "ç·šä¸Šæª”æ¡ˆ"], horizontal=True)

    file_name_for_logic = None

    if input_method == "æœ¬åœ°æª”æ¡ˆ":
        uploaded_file = st.file_uploader("PPTX", type=["pptx"], label_visibility="collapsed")
        if uploaded_file:
            st.session_state.source_bytes = uploaded_file.getvalue()
            file_name_for_logic = uploaded_file.name

    else:
        url_input = st.text_input("PPTX ç›´æ¥ä¸‹è¼‰ç¶²å€ (Direct URL)", placeholder="https://example.com/file.pptx")
        if url_input:
            if not url_input.lower().endswith(".pptx"):
                st.warning("âš ï¸ ç¶²å€çµå°¾ä¼¼ä¹ä¸æ˜¯ .pptxï¼Œè«‹ç¢ºèªç¶²å€æ­£ç¢ºæ€§ã€‚")

            fake_name = url_input.split("/")[-1].split("?")[0]
            if not fake_name.lower().endswith(".pptx"):
                fake_name += ".pptx"

            if st.button("ğŸ“¥ ä¸‹è¼‰ä¸¦è¼‰å…¥", use_container_width=True):
                with st.spinner("æ­£åœ¨ä¸‹è¼‰æª”æ¡ˆ..."):
                    try:
                        st.session_state.source_bytes = download_bytes_from_url(url_input)
                        file_name_for_logic = fake_name
                        st.success("ä¸‹è¼‰æˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"ä¸‹è¼‰å¤±æ•—: {e}")

    # è§£æ PPTï¼ˆç•¶æª”åè®Šæ›´æ‰é‡æ–°è®€ï¼‰
    if file_name_for_logic and st.session_state.source_bytes:
        if st.session_state.current_file_name != file_name_for_logic:
            # å¯«å…¥ workspaceï¼ˆâœ… ä¸æœƒå†ç™¼ç”Ÿ source.pptx è¢« cleanup åˆªæ‰é€ æˆ Package not foundï¼‰
            source_path = write_source_to_workspace(st.session_state.source_bytes)

            # è¼‰å…¥æ­·å²ä»»å‹™
            st.session_state.split_jobs = load_history(file_name_for_logic) or []

            # è§£æé é¢ï¼ˆcacheï¼‰
            with st.spinner("è§£ææª”æ¡ˆä¸­..."):
                try:
                    total_slides, preview_data = parse_ppt_preview(st.session_state.source_bytes)
                    st.session_state.ppt_meta = {"total_slides": total_slides, "preview_data": preview_data}
                    st.session_state.current_file_name = file_name_for_logic
                    st.success(f"âœ… å·²è®€å–ï¼š{file_name_for_logic} (å…± {total_slides} é )")
                except Exception as e:
                    st.error(f"æª”æ¡ˆè™•ç†å¤±æ•—: {e}")
                    st.session_state.current_file_name = None

# Step 2/3ï¼ˆåƒ…ç•¶å·²è¼‰å…¥ï¼‰
if st.session_state.current_file_name:
    total_slides = st.session_state.ppt_meta["total_slides"]
    preview_data = st.session_state.ppt_meta["preview_data"]

    with st.expander("ğŸ‘ï¸ é»æ“ŠæŸ¥çœ‹ã€Œé ç¢¼èˆ‡æ¨™é¡Œå°ç…§è¡¨ã€", expanded=False):
        st.dataframe(preview_data, use_container_width=True, height=250, hide_index=True)

    with st.container(border=True):
        head_l, head_r = st.columns([3, 1])
        head_l.subheader("ğŸ“ æ­¥é©ŸäºŒï¼šè¨­å®šæ‹†åˆ†ä»»å‹™")
        if head_r.button("â• æ–°å¢ä»»å‹™", type="primary", use_container_width=True):
            add_split_job(total_slides)

        if not st.session_state.split_jobs:
            st.info("â˜ï¸ å°šæœªå»ºç«‹ä»»å‹™ï¼Œè«‹é»æ“Šä¸Šæ–¹æŒ‰éˆ•æ–°å¢ã€‚")

        for i, job in enumerate(st.session_state.split_jobs):
            with st.container(border=True):
                st.markdown(f"**ğŸ“„ ä»»å‹™ {i+1}**")
                c1, c2, c3 = st.columns([3, 1.3, 1.3])
                job["filename"] = c1.text_input("æª”å", value=job["filename"], key=f"f_{job['id']}", placeholder="ä¾‹å¦‚ï¼šæ¸…æ½”æ¡ˆä¾‹A")
                job["start"] = c2.number_input("èµ·å§‹é ", 1, total_slides, job["start"], key=f"s_{job['id']}")
                job["end"] = c3.number_input("çµæŸé ", 1, total_slides, job["end"], key=f"e_{job['id']}")

                m1, m2, m3, m4 = st.columns(4)
                job["category"] = m1.selectbox("é¡å‹", ["æ¸…æ½”", "é…é€", "è³¼ç‰©", "AURO"], key=f"cat_{job['id']}")
                job["subcategory"] = m2.text_input("å­åˆ†é¡", value=job["subcategory"], key=f"sub_{job['id']}")
                job["client"] = m3.text_input("å®¢æˆ¶", value=job["client"], key=f"cli_{job['id']}")
                job["keywords"] = m4.text_input("é—œéµå­—", value=job["keywords"], key=f"key_{job['id']}")

                if st.button("ğŸ—‘ï¸ åˆªé™¤æ­¤ä»»å‹™", key=f"d_{job['id']}", type="secondary"):
                    remove_split_job(i)
                    st.rerun()

        save_history(st.session_state.current_file_name, st.session_state.split_jobs)

    with st.container(border=True):
        st.subheader("ğŸš€ é–‹å§‹åŸ·è¡Œ")
        auto_clean = st.checkbox("ä»»å‹™å®Œæˆå¾Œè‡ªå‹•æ¸…é™¤æš«å­˜æª”", value=True)

        if st.button("åŸ·è¡Œè‡ªå‹•åŒ–æ’ç¨‹", type="primary", use_container_width=True):
            if not st.session_state.split_jobs:
                st.error("è«‹è‡³å°‘è¨­å®šä¸€å€‹æ‹†åˆ†ä»»å‹™ï¼")
            else:
                errs = validate_jobs(st.session_state.split_jobs, total_slides)
                if errs:
                    for e in errs:
                        st.error(e)
                    st.error("â›”ï¸ è«‹ä¿®æ­£éŒ¯èª¤å¾Œå†åŸ·è¡Œã€‚")
                else:
                    if not bot:
                        st.error("âŒ æ©Ÿå™¨äººæœªåˆå§‹åŒ–ï¼ˆSecrets/æ†‘è­‰å•é¡Œï¼‰ã€‚")
                    else:
                        source_path = os.path.join(WORK_DIR, SOURCE_FILENAME)
                        file_prefix = os.path.splitext(st.session_state.current_file_name)[0]
                        execute_automation_logic(bot, source_path, file_prefix, st.session_state.split_jobs, auto_clean)
